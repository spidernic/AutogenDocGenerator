# Code Documentation Generator

This project analyzes code repositories and generates comprehensive documentation, including purpose, functionalities, architecture, notable features, libraries used, and usage examples. It utilizes OpenAI's language models via the AutoGen framework.

## Project structure
```
your_project/
├── 
└── src
      └── code_documentation_generator.py  # Your main script
├── config.yaml                            # Configuration file you just created
├── .env                                   # Environment variables file with your API key
├── debug.log                              # Log file generated by the script
└── [Your Repository]                      # The repository you want to analyze
```

## Table of Contents

- [Features](#features)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [Output](#output)
- [Logging](#logging)
- [Customization](#customization)
- [Contributing](#contributing)
- [License](#license)


## Features

- **Automated Code Analysis**: Analyzes code files across multiple programming languages.
- **Dependency Extraction**: Extracts and lists dependencies from common dependency files.
- **Concurrent Processing**: Utilizes multithreading to analyze multiple files concurrently.
- **Robust Error Handling**: Includes retry mechanisms and rate limiting to handle API rate limits and transient errors.
- **JSON and Markdown Output**: Generates documentation in both JSON and Markdown formats.
- **Configurable**: Uses a `config.yaml` file for easy configuration management.

## Prerequisites

- **Python 3.11 or higher**
- **OpenAI API Key**: Required for accessing OpenAI's language models. GPT-4o is suggested since it manages very well agent communication in JSON.
- **Git**: If analyzing repositories managed with Git (optional).

## Installation

1. **Clone the Repository**:

   ```bash
   git clone https://github.com/your_username/code-documentation-generator.git
   cd code-documentation-generator
   ```

2. **Create a Virtual Environment** (optional but recommended):

   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows use: venv\Scripts\activate
   ```

   ... or if you prefer miniconda

   ```bash
   conda create -n docgen -y
   conda activate docgen
   ```

3. **Install Required Python Packages**:

   ```bash
   pip install -r requirements.txt
   ```

   **Note**: If you don't have a `requirements.txt` file, you can install the packages directly:

   ```bash
   pip install python-dotenv pyyaml jsonschema 
   ```

## Configuration

### Environment Variables

1. **Create a `.env` File**:

   In the root directory of the project, create a file named `.env` and add your OpenAI API key and model name:

   ```dotenv
   # .env

   OPEN_AI_API_KEY='your_openai_api_key'
   MODEL_NAME='gpt-4'  # or 'gpt-3.5-turbo'
   ```

   **Important**: Keep your API key secure and do not share this file publicly.

### Configuration File

2. **Create a `config.yaml` File**:

   In the same directory, create a file named `config.yaml` with the following content:

   ```yaml
   # config.yaml

   semilla: 42
   temperature: 0.2
   max_api_calls_per_minute: 60
   repo_path: 'path_to_your_repository'
   ```

   **Parameters**:

   - `semilla`: Seed value for random number generation. **IMPORTANT**: In Microsoft Autogen, if you use the same seed between runs, **you will probably benefit from the Autogen ***.cache***, and you will save in inference costs**.
   - `temperature`: Controls the randomness of AI responses (0.0 to 1.0).
   - `max_api_calls_per_minute`: Set according to your OpenAI API rate limit.
   - `repo_path`: Path to the code repository you want to analyze.

## Usage

Run the script using the following command:

```bash
python code_documentation_generator.py
```

## Output

- **JSON File**: The script generates `output.json` containing the detailed analysis and documentation.
- **Markdown File**: A `output.md` file is also created, providing a human-readable version of the documentation, although very basic, just for testing purposes.

## Logging

- **Log File**: The script outputs logs to `debug.log` for troubleshooting and audit purposes.
- **Console Output**: Logs are also printed to the console for real-time monitoring.

## Customization

- **Adjusting Analysis Scope**: Modify the file extensions in the `file_paths` list within `RepositoryProcessor` to include or exclude specific file types.
- **Extending Dependency Analysis**: Enhance `DependencyAnalyzer` to support additional languages or dependency files.
- **Changing AI Model**: Update the `MODEL_NAME` in the `.env` file to switch between different OpenAI models.

## Contributing

Contributions are welcome! Please follow these steps:

1. **Fork the Repository**: Click the "Fork" button at the top right of this page.
2. **Clone Your Fork**:

   ```bash
   git clone https://github.com/spidernic/autogen-code-documentation-generator.git
   ```

3. **Create a Feature Branch**:

   ```bash
   git checkout -b feature/your_feature_name
   ```

4. **Commit Your Changes**:

   ```bash
   git commit -am 'Add some feature'
   ```

5. **Push to the Branch**:

   ```bash
   git push origin feature/your_feature_name
   ```

6. **Open a Pull Request**: Go to the original repository and open a pull request.

## License

This project is licensed under the [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0).

---

## Additional Information

### Troubleshooting

- **API Rate Limits**: If you encounter rate limit errors, consider adjusting `max_api_calls_per_minute` in `config.yaml`.
- **Invalid JSON Responses**: The script includes mechanisms to handle and correct invalid JSON from the AI model. Check `debug.log` for details.
- **Encoding Issues**: Files are read using UTF-8 encoding with errors ignored. If you face issues, ensure your files are properly encoded.

### Dependencies

- **python-dotenv**: Loads environment variables from a `.env` file.
- **pyyaml**: Parses YAML files for configuration.
- **jsonschema**: Validates JSON data against a schema.
- **pkg_resources**: Parses Python package requirement files.

### Contact

For any questions or support, please open an issue or contact: Nic Cravino **Email**: spidernic@me.com / ncravino@mac.com **LinkedIn**: [Nic Cravino](https://www.linkedin.com/in/nic-cravino)

---

### Acknowledgments

- **OpenAI**: For providing the powerful language models used in this project.
- **Contributors**: Thanks to all who have contributed to improving this project.

